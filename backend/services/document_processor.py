from typing import List, Tuple, Dict, Any
import re
from pypdf import PdfReader
from sklearn.cluster import KMeans
import numpy as np


class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ (íŒŒì‹±, ì²­í‚¹, í† í”½ í´ëŸ¬ìŠ¤í„°ë§)"""

    def __init__(self, chunk_size: int = 800, overlap_ratio: float = 0.2):
        """
        Args:
            chunk_size: ì²­í¬ í¬ê¸° (ë¬¸ì ë‹¨ìœ„)
            overlap_ratio: ì˜¤ë²„ë© ë¹„ìœ¨ (0.2 = 20%)
        """
        self.chunk_size = chunk_size
        self.overlap = int(chunk_size * overlap_ratio)

    def extract_text_from_file(self, file_path: str, file_type: str) -> str:
        """
        íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            file_type: íŒŒì¼ íƒ€ì… (txt, pdf)

        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        if file_type == "txt":
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()
        elif file_type == "pdf":
            text = self._extract_text_from_pdf(file_path)
        else:
            raise ValueError(f"Unsupported file type: {file_type}")

        return text

    def _extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n\n"
        return text

    def chunk_text(self, text: str) -> List[str]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹)

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸

        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        # í…ìŠ¤íŠ¸ ì •ë¦¬ (ê³¼ë„í•œ ê³µë°± ì œê±°)
        text = re.sub(r'\n\s*\n', '\n\n', text)  # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬
        text = re.sub(r' +', ' ', text)  # ì—°ì†ëœ ê³µë°± ì •ë¦¬

        chunks = []
        start = 0

        while start < len(text):
            # ì²­í¬ ë ìœ„ì¹˜ ê³„ì‚°
            end = start + self.chunk_size

            # í…ìŠ¤íŠ¸ ëì„ ë„˜ì§€ ì•Šë„ë¡
            if end >= len(text):
                chunks.append(text[start:].strip())
                break

            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸° (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ì°¾ê¸°)
            chunk_text = text[start:end]
            last_sentence_end = max(
                chunk_text.rfind('. '),
                chunk_text.rfind('! '),
                chunk_text.rfind('? '),
                chunk_text.rfind('.\n'),
                chunk_text.rfind('!\n'),
                chunk_text.rfind('?\n')
            )

            if last_sentence_end > 0:
                end = start + last_sentence_end + 1
                chunks.append(text[start:end].strip())
                start = end - self.overlap  # ì˜¤ë²„ë© ì ìš©
            else:
                # ë¬¸ì¥ ê²½ê³„ë¥¼ ëª» ì°¾ìœ¼ë©´ ê·¸ëƒ¥ ìë¥´ê¸°
                chunks.append(chunk_text.strip())
                start = end - self.overlap

        # ë¹ˆ ì²­í¬ ì œê±°
        chunks = [c for c in chunks if len(c.strip()) > 0]

        return chunks

    def cluster_chunks_into_subsessions(
        self,
        chunk_embeddings: List[List[float]],
        min_clusters: int = 3,
        max_clusters: int = 8
    ) -> Tuple[List[int], int]:
        """
        ì²­í¬ ì„ë² ë”©ì„ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ ì„œë¸Œì„¸ì…˜ìœ¼ë¡œ ë¶„í• 

        Args:
            chunk_embeddings: ì²­í¬ ì„ë² ë”© ë²¡í„° ëª©ë¡
            min_clusters: ìµœì†Œ í´ëŸ¬ìŠ¤í„° ìˆ˜
            max_clusters: ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ìˆ˜

        Returns:
            (cluster_labels, num_clusters)
            - cluster_labels: ê° ì²­í¬ì˜ í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”
            - num_clusters: ì´ í´ëŸ¬ìŠ¤í„° ìˆ˜
        """
        num_chunks = len(chunk_embeddings)

        # ì²­í¬ ìˆ˜ê°€ ì ìœ¼ë©´ í´ëŸ¬ìŠ¤í„° ìˆ˜ ì¡°ì •
        num_clusters = min(max(min_clusters, num_chunks // 5), max_clusters)
        num_clusters = min(num_clusters, num_chunks)  # ì²­í¬ ìˆ˜ë³´ë‹¤ ë§ì„ ìˆ˜ ì—†ìŒ

        if num_clusters <= 1:
            # í´ëŸ¬ìŠ¤í„°ë§ì´ ì˜ë¯¸ ì—†ëŠ” ê²½ìš°
            return [0] * num_chunks, 1

        # K-Means í´ëŸ¬ìŠ¤í„°ë§
        embeddings_array = np.array(chunk_embeddings)
        kmeans = KMeans(
            n_clusters=num_clusters,
            random_state=42,
            n_init=10
        )
        cluster_labels = kmeans.fit_predict(embeddings_array)

        return cluster_labels.tolist(), num_clusters

    def generate_subsession_title(self, chunks: List[str]) -> str:
        """
        ì„œë¸Œì„¸ì…˜ ì œëª© ìƒì„± (ì²« ë¬¸ì¥ ë˜ëŠ” í‚¤ì›Œë“œ ê¸°ë°˜)

        Args:
            chunks: ì„œë¸Œì„¸ì…˜ì— ì†í•œ ì²­í¬ ëª©ë¡

        Returns:
            ì„œë¸Œì„¸ì…˜ ì œëª©
        """
        if not chunks:
            return "Untitled Subsession"

        # ì²« ë²ˆì§¸ ì²­í¬ì˜ ì²« ë¬¸ì¥ ì¶”ì¶œ
        first_chunk = chunks[0]
        sentences = re.split(r'[.!?]\s+', first_chunk)

        if sentences:
            title = sentences[0].strip()
            # ë„ˆë¬´ ê¸´ ì œëª©ì€ ìë¥´ê¸°
            if len(title) > 60:
                title = title[:57] + "..."
            return title

        return "Untitled Subsession"


def extract_text_from_bytes(file_bytes: bytes, file_type: str) -> str:
    """
    ë°”ì´íŠ¸ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (Streamlit ì—…ë¡œë“œ íŒŒì¼ìš©)

    Args:
        file_bytes: íŒŒì¼ ë°”ì´íŠ¸ ë°ì´í„°
        file_type: íŒŒì¼ íƒ€ì… (txt, pdf)

    Returns:
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    """
    if file_type == "txt":
        text = file_bytes.decode("utf-8")
    elif file_type == "pdf":
        from io import BytesIO
        reader = PdfReader(BytesIO(file_bytes))
        text = ""
        print(f"ğŸ“„ PDF has {len(reader.pages)} pages")

        for i, page in enumerate(reader.pages):
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n\n"
                print(f"âœ… Page {i+1}: extracted {len(page_text)} characters")
            else:
                print(f"âš ï¸ Page {i+1}: no text extracted")

        print(f"ğŸ“ Total extracted text: {len(text)} characters")

        # í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ OCR ì‹œë„
        min_chars_per_page = 100  # í˜ì´ì§€ë‹¹ ìµœì†Œ 100ì ê¸°ëŒ€
        if len(text) < len(reader.pages) * min_chars_per_page:
            print(f"âš ï¸ Low text density detected. Attempting OCR...")
            ocr_text = _extract_text_with_ocr(file_bytes)
            if ocr_text and len(ocr_text) > len(text):
                print(f"âœ… OCR extracted {len(ocr_text)} characters (better than {len(text)})")
                text = ocr_text
            else:
                print(f"âŒ OCR failed or produced less text")

        if not text.strip():
            print("âŒ WARNING: No text extracted from PDF!")
    else:
        raise ValueError(f"Unsupported file type: {file_type}")

    return text


def _extract_text_with_ocr(pdf_bytes: bytes) -> str:
    """
    OCRì„ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì´ë¯¸ì§€ ê¸°ë°˜ PDFìš©)

    Args:
        pdf_bytes: PDF ë°”ì´íŠ¸ ë°ì´í„°

    Returns:
        OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    """
    try:
        from io import BytesIO
        from pdf2image import convert_from_bytes
        import pytesseract

        print("ğŸ” Starting OCR process...")

        # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        images = convert_from_bytes(pdf_bytes, dpi=200)
        print(f"ğŸ“· Converted {len(images)} pages to images")

        text = ""
        for i, image in enumerate(images):
            # OCR ìˆ˜í–‰
            page_text = pytesseract.image_to_string(image, lang='eng+deu')  # ì˜ì–´+ë…ì¼ì–´
            if page_text.strip():
                text += page_text + "\n\n"
                print(f"âœ… OCR Page {i+1}: extracted {len(page_text)} characters")
            else:
                print(f"âš ï¸ OCR Page {i+1}: no text extracted")

            # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì´ë¯¸ì§€ í•´ì œ
            image.close()

        print(f"ğŸ“ Total OCR text: {len(text)} characters")
        return text

    except ImportError as e:
        print(f"âŒ OCR libraries not installed: {e}")
        print("ğŸ’¡ Install with: pip install pdf2image pytesseract")
        print("ğŸ’¡ Also install tesseract: brew install tesseract (macOS)")
        return ""
    except Exception as e:
        print(f"âŒ OCR failed: {str(e)}")
        return ""
